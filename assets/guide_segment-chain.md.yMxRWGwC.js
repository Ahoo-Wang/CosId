import{_ as t}from"./chunks/SegmentChainId.DWY8C3dk.js";import{_ as o}from"./chunks/Throughput-Of-SegmentChainId.PChbVaDv.js";import{_ as n,c as r,a2 as s,o as d}from"./chunks/framework.DA3SO-Rd.js";const u=JSON.parse('{"title":"号段链模式","description":"","frontmatter":{},"headers":[],"relativePath":"guide/segment-chain.md","filePath":"guide/segment-chain.md","lastUpdated":1736921966000}'),i={name:"guide/segment-chain.md"};function g(c,e,m,a,S,l){return d(),r("div",null,e[0]||(e[0]=[s('<h1 id="号段链模式" tabindex="-1">号段链模式 <a class="header-anchor" href="#号段链模式" aria-label="Permalink to &quot;号段链模式&quot;">​</a></h1><p align="center"><img src="'+t+'" alt="SegmentChainId"></p><p><strong>SegmentChainId</strong>是<strong>SegmentId</strong>增强版，相比于<strong>SegmentId</strong>有以下优势：</p><ul><li>稳定性：<strong>SegmentId</strong>的稳定性问题（P9999=46.624(us/op)）主要是因为号段用完之后同步进行<code>NextMaxId</code>的获取导致的（会产生网络IO）。 <ul><li><strong>SegmentChainId</strong> （P9999=0.208(us/op)）引入了新的角色<strong>PrefetchWorker</strong>用以维护和保证<strong>安全距离</strong>，理想情况下使得获取ID的线程几乎完全不需要进行同步的等待<code>NextMaxId</code>获取，性能可达到近似 <code>AtomicLong</code> 的 <em>TPS 性能:12743W+/s</em> <a href="./faq/perf-test.html">JMH 基准测试</a> 。</li></ul></li><li>适应性：从<strong>SegmentId</strong>介绍中我们知道了影响<strong>ID乱序</strong>的因素有俩个：集群规模、<code>Step</code>大小。集群规模是我们不能控制的，但是<code>Step</code>是可以调节的。 <ul><li><code>Step</code>应该近可能小才能使得<strong>ID单调递增</strong>的可能性增大。</li><li><code>Step</code>太小会影响吞吐量，那么我们如何合理设置<code>Step</code>呢？答案是我们无法准确预估所有时点的吞吐量需求，那么最好的办法是吞吐量需求高时，Step自动增大，吞吐量低时Step自动收缩。</li><li><strong>SegmentChainId</strong>引入了<strong>饥饿状态</strong>的概念，<strong>PrefetchWorker</strong>会根据<strong>饥饿状态</strong>检测当前<strong>安全距离</strong>是否需要膨胀或者收缩，以便获得吞吐量与有序性之间的权衡，这便是<strong>SegmentChainId</strong>的自适应性。</li></ul></li></ul><h2 id="为什么需要segmentchainid" tabindex="-1">为什么需要<em>SegmentChainId</em> <a class="header-anchor" href="#为什么需要segmentchainid" aria-label="Permalink to &quot;为什么需要*SegmentChainId*&quot;">​</a></h2><p align="center"><img src="'+t+'" alt="SegmentChainId"></p><p>通过<strong>SegmentChainId</strong>设计图中我们可以看到，号段链模式新增了一个角色<strong>PrefetchWorker</strong>。 <strong>PrefetchWorker</strong>主要的职责是维护和保证号段链头部到尾部的<strong>安全距离</strong>，也可以近似理解为缓冲距离。 有了安全距离的保障不难得出的结论是所有获取ID的线程只要从进程内存的号段里边获取下次ID即可，理想情况下不需要再进行<code>NextMaxId</code>（向号段分发器请求<code>NextMaxId</code>，网络IO）的，所以性能可以达到近似<code>AtomicLong</code> 的 <em>TPS 性能:12743W+/s</em>的级别。</p><p><strong>SegmentChainId</strong>是<strong>SegmentId</strong>的增强版，相比于<strong>SegmentId</strong>有以下优势：</p><ul><li>TPS性能：可达到近似 <code>AtomicLong</code> 的 <em>TPS 性能:12743W+/s</em> <a href="./faq/perf-test.html">JMH 基准测试</a>。通过引入了新的角色<strong>PrefetchWorker</strong>用以维护和保证<strong>安全距离</strong>，理想情况下使得获取ID的线程几乎完全不需要进行同步的等待<code>NextMaxId</code>获取。</li><li>稳定性：P9999=0.208(us/op)，通过上面的TPS性能描述中我们可以看到，<strong>SegmentChainId</strong>消除了同步等待的问题，所以稳定性问题也因此迎刃而解。</li><li>适应性：从<strong>SegmentId</strong>介绍中我们知道了影响<strong>ID乱序</strong>的因素有俩个：集群规模、<code>Step</code>大小。集群规模是我们不能控制的，但是<code>Step</code>是可以调节的。 <ul><li><code>Step</code>应该尽可能小才能使得<strong>ID单调递增</strong>的可能性增大。</li><li><code>Step</code>太小会影响吞吐量，那么我们如何合理设置<code>Step</code>呢？答案是我们无法准确预估所有时点的吞吐量需求，那么最好的办法是吞吐量需求高时，Step自动增大，吞吐量低时Step自动收缩。</li><li><strong>SegmentChainId</strong>引入了<strong>饥饿状态</strong>的概念，<strong>PrefetchWorker</strong>会根据<strong>饥饿状态</strong>检测当前<strong>安全距离</strong>是否需要膨胀或者收缩，以便获得吞吐量与有序性之间的权衡，这便是<strong>SegmentChainId</strong>的自适应性。</li><li>所以在使用<strong>SegmentChainId</strong>时我们可以配置一个比较小的<code>Step</code>步长，然后由<strong>PrefetchWorker</strong>根据吞吐量需求自动调节<strong>安全距离</strong>，来自动伸缩步长。</li></ul></li></ul><h2 id="redisidsegmentdistributor、jdbcidsegmentdistributor-均能够达到tps-1-2亿-s" tabindex="-1">RedisIdSegmentDistributor、JdbcIdSegmentDistributor 均能够达到TPS=1.2亿/s？ <a class="header-anchor" href="#redisidsegmentdistributor、jdbcidsegmentdistributor-均能够达到tps-1-2亿-s" aria-label="Permalink to &quot;RedisIdSegmentDistributor、JdbcIdSegmentDistributor 均能够达到TPS=1.2亿/s？&quot;">​</a></h2><p align="center"><img src="'+o+'" alt="Throughput-Of-SegmentChainId"></p><p>上面的两张图给许多同学带来了困扰，为什么在<code>Step=1000</code>的时候<em>RedisIdSegmentDistributor</em>、<em>JdbcIdSegmentDistributor</em>TPS性能几乎一致(TPS=1.2亿/s)。 <em>RedisIdSegmentDistributor</em>应该要比<em>JdbcIdSegmentDistributor</em>性能更高才对啊，为什么都能达到<em>AtomicLong</em>性能上限呢？ 如果我说当<code>Step=1</code>时，只要基准测试的时间够长，那么他们依然能够达到<em>AtomicLong</em>性能级别(TPS=1.2亿/s)，你会不会更加困惑。 其实这里的<em>障眼法</em>是<strong>PrefetchWorker</strong>的<strong>饥饿膨胀</strong>导致的，<em>SegmentChainId</em>的极限性能跟分发器的TPS性能没有直接关系，因为最终都可以因饥饿膨胀到性能上限，只要给足够的时间膨胀。 而为什么在上图的<code>Step=1</code>时TPS差异还是很明显的，这是因为<em>RedisIdSegmentDistributor</em>膨胀得更快，而基准测试又没有给足测试时间而已。</p><p><strong>SegmentChainId</strong>基准测试<em>TPS极限性能</em>可以近似使用以下的公式的表示：</p><p><code>TPS(SegmentChainId)极限值=(Step*Expansion)*TPS(IdSegmentDistributor)*T/s&lt;=TPS(AtomicLong)</code></p><ol><li><code>&lt;=TPS(AtomicLong)</code>：因为<em>SegmentChainId</em>的内部号段就是使用的<code>AtomicLong</code>，所以这是性能上限。</li><li><code>Step*Expansion</code>：<em>Expansion</em>可以理解为饥饿膨胀系数，默认的饥饿膨胀系数是2。在<em>MySqlChainIdBenchmark</em>、<em>MySqlChainIdBenchmark</em>基准测试中这个值是一样的。</li><li><code>TPS(IdSegmentDistributor)</code>: 这是公式中唯一的不同。指的是请求号段分发器<code>NextMaxId</code>的TPS。</li><li><code>T</code>: 可以理解为基准测试运行时常。</li></ol><p>从上面的公式中不难看出<em>RedisChainIdBenchmark</em>、<em>MySqlChainIdBenchmark</em>主要差异是分发器的TPS性能。 分发器的<code>TPS(IdSegmentDistributor)</code>越大，达到<code>TPS(AtomicLong)</code>所需的<code>T</code>就越少。但只要<code>T</code>足够长，那么任何分发器都可以达到近似<code>TPS(AtomicLong)</code>。 这也就解释了为什么不同TPS性能级别的号段分发器(<strong>IdSegmentDistributor</strong>)都可以达到TPS=1.2亿/s。</p>',16)]))}const P=n(i,[["render",g]]);export{u as __pageData,P as default};
